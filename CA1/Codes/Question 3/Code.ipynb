{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Question 3 - support vector machine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "from math import sqrt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = 0\n",
    "TEST = 1\n",
    "NUMBER_OF_CLASSES = 10\n",
    "NUMBER_OF_FOLDS = 5\n",
    "MU = 0\n",
    "BATCH = 10\n",
    "SIGMA = 0.1\n",
    "CONSTANT = 0\n",
    "REGRESSIVE = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "\n",
    "    data = pd.read_csv(filename)\n",
    "    labels = np.array(data.iloc[:,0])\n",
    "    data.drop(data.columns[0], 1, inplace=True)\n",
    "    return data.to_numpy(), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_names = os.listdir('Question 3')\n",
    "\n",
    "train_data, train_labels = read_data(file_names[TRAIN])\n",
    "test_data, test_labels = read_data(file_names[TEST])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(number_of_folds, fold_number, x, y):\n",
    "\n",
    "\n",
    "    n, m = np.shape(train_data)\n",
    "\n",
    "    begin = int(np.ceil(n / number_of_folds* fold_number))\n",
    "    end = int(np.ceil(n / number_of_folds* (fold_number + 1)))\n",
    "\n",
    "    y_train = np.array([])\n",
    "    x_train = np.zeros((0, m))\n",
    "\n",
    "    if fold_number > 0:\n",
    "        y_train = y[:begin]\n",
    "        x_train = x[:begin, :]\n",
    "    if fold_number < (number_of_folds - 1):\n",
    "        y_train = np.concatenate((y_train, y[end:y.size]))\n",
    "        x_train = np.concatenate((x_train, x[end:y.size, :]))\n",
    "\n",
    "    x_test = x[begin : end, :]\n",
    "    y_test = y[begin : end]\n",
    "\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient For Stochastic Form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(lambdaa, b, w, x, y):\n",
    "\n",
    "    if (1 - y*(np.dot(w, x) - b)) > 0:\n",
    "        gradient_b, gradient_w = y, 2*lambdaa*w - y*x\n",
    "    else:\n",
    "        gradient_b, gradient_w = 0, 2*lambdaa*w\n",
    "\n",
    "    return gradient_b, gradient_w "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient For Batch Form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_gradient(lambdaa, b, w, x, y):\n",
    "\n",
    "    gradient_b = 0\n",
    "    gradient_w = 2*lambdaa*w\n",
    "    for k in range(10):\n",
    "        if (1-y[k]*(np.dot(w, x[k,:])-b)) > 0:\n",
    "            gradient_b += y[k] / BATCH\n",
    "            gradient_w += -y[k]*x[k,:]\n",
    "        else:\n",
    "            gradient_b, gradient_w = gradient_b, gradient_w\n",
    "\n",
    "    return gradient_b, gradient_w\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the data for each epoch - Stochastic Form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_each_epoch(w, b, lambdaa, alpha, train_data, train_labels):\n",
    "\n",
    "    random_indices = np.arange(train_data.shape[0])\n",
    "    np.random.shuffle(random_indices)\n",
    "\n",
    "    for k in range(train_data.shape[0]):\n",
    "\n",
    "        gradient_b, gradient_w = gradient(lambdaa, b, w, train_data[random_indices[k], :], train_labels[random_indices[k]])\n",
    "        b -= alpha*gradient_b\n",
    "        w -= alpha*gradient_w\n",
    "\n",
    "    return w, b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the data for each epoch - Batch Form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_train_each_epoch(w, b, lambdaa, alpha, train_data, train_labels):\n",
    "    \n",
    "    for k in range(0, train_data.shape[0], BATCH):\n",
    "\n",
    "        gradient_b, gradient_w = batch_gradient(lambdaa, b, w, train_data[k:k+BATCH, :], train_labels[k:k+BATCH])\n",
    "        b -= alpha*gradient_b\n",
    "        w -= alpha*gradient_w\n",
    "\n",
    "    return w, b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning New Labels (1 and -1) For One vs. All Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def assign_new_labels(number_of_classes, x_size, y, label):\n",
    "\n",
    "    new_label = np.zeros(x_size)\n",
    "    for i in range(x_size):\n",
    "        new_label[i] = 1 if y[i] == label else -1\n",
    "\n",
    "    return new_label           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(X, Y, w, b):\n",
    "    correct_predict = 0\n",
    "    for i in range(X.shape[0]):\n",
    "        if Y[i]*(np.dot(w, X[i,:])-b) > 0:\n",
    "            correct_predict += 1\n",
    "    return correct_predict/X.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the Best Lambda For Each Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_lambda(x, y):\n",
    "\n",
    "    epochs = 40\n",
    "    lambdas = [10**-10, 10**-8, 10**-6, 10**-4, 10**-2, 1]\n",
    "    best_lambdaa = np.zeros(NUMBER_OF_CLASSES)\n",
    "    for label in range(NUMBER_OF_CLASSES):\n",
    "        new_labels = assign_new_labels(NUMBER_OF_CLASSES, x, y, label)\n",
    "        best_acc_lambdaa = np.zeros(len(lambdas))\n",
    "        for l, lambdaa in enumerate(lambdas): \n",
    "            best_acc_fold = np.zeros(NUMBER_OF_FOLDS)\n",
    "            for fold_number in range(NUMBER_OF_FOLDS):\n",
    "                temp_predict_test = np.zeros(epochs)\n",
    "                b = 0 \n",
    "                w = np.random.normal(MU, SIGMA, x.shape[1])\n",
    "                x_train, y_train, x_test, y_test = cross_validation(NUMBER_OF_FOLDS, fold_number, x, new_labels)\n",
    "                for epoch in range(epochs):\n",
    "                    #alpha = 0.1/((epoch+1)**2)\n",
    "                    alpha = 0.01\n",
    "                    w, b = train_each_epoch(w, b, lambdaa, alpha, x_train, y_train)\n",
    "                    temp_predict_test[epoch] = predict(x_test, y_test, w, b)\n",
    "\n",
    "                best_acc_fold[fold_number] = np.amax(temp_predict_test)\n",
    "            best_acc_lambdaa[l] = np.amax(best_acc_fold)\n",
    "        best_lambdaa[label] = lambdas[np.argmax(best_acc_lambdaa)]\n",
    "        print(\"Accuracy of each lambda:\", best_acc_lambdaa)\n",
    "        print(\"lambda of label\", label, \"is :\", best_lambdaa[label])\n",
    "    return best_lambdaa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Function + L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(lambdaa, x, y, b, w):\n",
    "\n",
    "    cost = lambdaa*(np.linalg.norm(w)**2)\n",
    "    for i in range(x.shape[0]):\n",
    "        cost += (1/x.shape[0])*max(0, 1-y[i]*(np.dot(w, x[i,:]) - b))\n",
    "    return cost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(predict, test_labels):\n",
    "    count = 0\n",
    "    acc = []\n",
    "    for i in range(predict.shape[0]):\n",
    "        if np.count_nonzero(predict[i,:]) ==  1:\n",
    "            if np.where(predict[i,:] == 1)[0][0] == test_labels[i]:\n",
    "                count += 1\n",
    "        acc.append(count/predict.shape[0])\n",
    "    print(\"Final accuracy for sgd:\", count/ predict.shape[0])\n",
    "    accuracy = count/ predict.shape[0]\n",
    "    return accuracy, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test(test_data, w, b, label, prediction):\n",
    "\n",
    "    for i in range(test_data.shape[0]):\n",
    "        if (np.dot(w, test_data[i,:])-b) > 1:\n",
    "            prediction[i, label] = 1\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Gradient Descent (Batch or Stochastic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(lambdas, train_data, train_labels, test_data, test_labels, label, prediction):\n",
    "\n",
    "    epochs = 100\n",
    "    lambdaa = lambdas[label]\n",
    "    new_labels = assign_new_labels(NUMBER_OF_CLASSES, train_data.shape[0], train_labels, label)\n",
    "    b = 0\n",
    "    w = np.random.normal(MU, SIGMA, train_data.shape[1])\n",
    "    cost = np.zeros(epochs)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        alpha = [10**-2, 0.1/((epoch+1)**2)] #10**2*0.97**(epoch)\n",
    "        w, b = train_each_epoch(w, b, lambdaa, alpha[CONSTANT], train_data, new_labels)\n",
    "        #w, b = batch_train_each_epoch(w, b, lambdaa, alpha[CONSTANT], train_data, new_labels)                 #uncomment if BGD\n",
    "        cost[epoch] = cost_function(lambdaa, train_data, new_labels, b, w)\n",
    "\n",
    "    predictions = predict_test(test_data, w, b, label, prediction)\n",
    "    return predictions, cost        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = np.array([10**-8, 10**-8, 10**-6, 10**-6, 0.0001, 10**-6, 10**-6, 10**-6, 10**-8, 10**-8])\n",
    "prediction = np.zeros((test_data.shape[0],10))\n",
    "\n",
    "for label in range(NUMBER_OF_CLASSES):\n",
    "    predictions, cost = gradient_descent(lambdas, train_data, train_labels, test_data, test_labels, label, prediction)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_const_BGD, acc = calculate_accuracy(predictions, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = 100\n",
    "\n",
    "# plt.plot(np.arange(epochs), cost_con, 'pink', label = 'SGD constant stepsize')\n",
    "# plt.plot(np.arange(epochs), cost_decay_BGD, 'gray', label = 'SGD decaying stepsize')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Loss Function')\n",
    "# plt.legend()\n",
    "# #plt.title('Stochastic Gradient Descent ')#with constant stepsize\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
